#数据转移
尽量减少主设间数据的的转移，最好是有支持front-side bus，直接读取。
如果是读取锁页，会隐含拷贝相关内容。最好是有全局内存的读合并。

#设备内存
全局内存和CPU区别不大
局部内存中主要是编译器安排放不定长数组、寄存器放不下的大数据结构、寄存器不够时的对象。
 使用--ptxas-options=-v编译时可以显示相关内容。

#内存并行
主要是对齐  \_\_aligned\_\_


#算术并行
几个nvcc编译指令
-ftz=true   非正规数归零
-prev-div=false 低精度除法  也可以用__fdividef(x,y)内置函数
-prev-sqrt=false 低精度开根
快速开根的倒数可以用rsqrtf(x) 比(1/sqrtf(x))快
快速开根用1/rsqrtf(x)。
三角函数x如果数量级较小(x<105615.0f)优化为较快的加、乘，否则(x <int::max().f)用较慢的双精度计算方法（吞吐量会减少一个数量级）。

整数的除法和求余操作很昂贵，最多耗费20条指令
如果n是2的幂，(i/n)相当于(i>>log2(n))，(i%n)相当于(i&(n-1))；如果 n 是字面量，编译器将执行这些转换。

#半精度算术
在CUDA中，half2和__nv_bfloat162都是特殊的数据类型，用于进行高效的并行计算。

half2是一个向量类型，包含两个16位浮点数，打包成一个32位类型1。这种类型可以用于执行一些特定的算术和数学函数2。例如，你可以使用__half22float2函数将half2类型转换为float2类型3。

__nv_bfloat162是NVIDIA为了支持bfloat16格式的计算而引入的数据类型2。bfloat16是一种浮点数格式，它只使用16位，但是提供了与32位浮点数相近的数值范围。这使得它在需要大量计算但不需要32位精度的应用中非常有用4。

这两种类型都可以提高GPU的计算效率，但是使用它们需要对CUDA编程有一定的了解。在使用这些类型时，你可能需要使用一些特定的函数来进行数据的转换和操作56。在选择使用哪种类型时，你需要根据你的具体需求和硬件能力来决定。24。

#控制流指令
在使用分支预测时，不会跳过任何依赖于控制条件的指令，但只有那些没有副作用的操作会被执行。

#同步指令
会耗费时间。

#减少内存抖动
只分配问题需要的量
需要时才分配，不用就释放
尝试使用cudaMallocManaged，设备内存不够就分配到主机，够了就迁回设备，”按需页面迁移“