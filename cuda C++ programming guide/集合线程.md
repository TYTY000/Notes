集合线程编程模型由以下元素组成：

用于表示协作线程组的数据类型；

获取 CUDA 启动 API 定义的隐式组的操作（例如，线程块）；

用于将现有组划分为新组的集合；

用于数据移动和操作的集体算法（例如 memcpy_async、reduce、scan）；

同步组内所有线程的操作；

检查集合属性的操作；

暴露低级别、特定于组且通常是硬件加速的操作的集合。

要编写高效的代码，最好使用专用组（通用组会损失大量编译时优化），并通过引用打算以某种协作方式使用这些线程的函数来传递这些组对象。

```c
__device__ int sum(const thread_block& g, int *x, int n) {
    // ...
    g.sync()
    return total;
}

__global__ void parallel_kernel(...) {
    // ...
    // Entire thread block must call sum
    thread_block tb = this_thread_block();
    sum(tb, x, n);
    // ...
}
```

#thread_block
隐式分组。
class thread_block;
Constructed via:
thread_block g = this_thread_block();

Public Member Functions:

static void sync(): 
Synchronize the threads named in the group, equivalent to g.barrier_wait(g.barrier_arrive())

thread_block::arrival_token barrier_arrive(): 
Arrive on the thread_block barrier, returns a token that needs to be passed into barrier_wait(). 

void barrier_wait(thread_block::arrival_token&& t): 
Wait on the thread_block barrier, takes arrival token returned from barrier_arrive() as a rvalue reference. 

static unsigned int thread_rank(): 
Rank of the calling thread within \[0, num_threads)

static dim3 group_index(): 
3-Dimensional index of the block within the launched grid

static dim3 thread_index(): 
3-Dimensional index of the thread within the launched block

static dim3 dim_threads(): 
Dimensions of the launched block in units of threads

static unsigned int num_threads(): 
Total number of threads in the group

cluster_group,grid_group,multi_grid_group  available in 9.0+.

以下两者为显示分组。
#group_partition
支持的父类有thread_group和thread_group_tile。
```c
  thread_block_tile<16> tiledPartition16 =
      tiled_partition<16>(threadBlockGroup);
```
#label_partition
实际使用中就是先分自组，然后马上跟个switch label进行分支，分支完调用subgroup.sync().
```c
auto subgroups = cg::labeled_partition(g, label);
switch (label) {
    case 0:
        // Code for subgroup 0
        break;
    case 1:
        // Code for subgroup 1
        break;
    // Add more cases as needed
}
subgroups.sync();
```
binary_partition类似label，但是只能0/1的谓词，还没确定。

cg::wait_prior\<N>
```c
#include <cooperative_groups.h>
#include <cooperative_groups/memcpy_async.h>

namespace cg = cooperative_groups;

__global__ void kernel(int *global_data) {
  cg::thread_block tb = cg::this_thread_block();
  constexpr size_t elementsPerThreadBlock = 16 * 1024 + 64;
  constexpr size_t elementsInShared = 128;
  __align__(16) __shared__ int local_smem[2][elementsInShared];
  int stage = 0;
  // First kick off an extra request
  size_t copy_count = elementsInShared;
  size_t index = copy_count;
  cg::memcpy_async(tb, local_smem[stage], elementsInShared, global_data,
                   elementsPerThreadBlock - index);
  while (index < elementsPerThreadBlock) {
    // Now we kick off the next request...
    cg::memcpy_async(tb, local_smem[stage ^ 1], elementsInShared,
                     global_data + index, elementsPerThreadBlock - index);
    // ... but we wait on the one before it
    cg::wait_prior<1>(tb);

    // Its now available and we can work with local_smem[stage] here
    // (...)
    //

    // Calculate the amount fo data that was actually copied, for the next
    // iteration.
    copy_count = min(elementsInShared, elementsPerThreadBlock - index);
    index += copy_count;

    // A cg::sync(tb) might be needed here depending on whether
    // the work done with local_smem[stage] can release threads to race ahead or
    // not Wrap to the next stage
    stage ^= 1;
  }
  cg::wait(tb);
  // The last local_smem[stage] can be handled here
}
```
#reduce
