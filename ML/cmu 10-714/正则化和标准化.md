#标准化
标准化（normalization）是一种预处理数据的方式，它可以使数据的分布更加均匀，减少数据的偏差和方差。标准化的方法有很多，例如最大最小归一化（min-max normalization），均值方差归一化（mean-variance normalization），或者单位向量归一化（unit vector normalization）等。标准化的目的是让数据的不同特征具有相似的尺度，从而避免某些特征对模型的影响过大或过小。

#正则化
正则化（regularization）是一种泛化模型参数的方式，它可以防止模型过拟合（overfitting）训练数据，提高模型在新数据上的泛化能力。正则化的方法也有很多，例如 L1 正则化（L1 regularization），L2 正则化（L2 regularization），或者 dropout 等。正则化的目的是让模型的参数更加简单，从而避免模型对训练数据的噪声或异常值过度敏感。
![[Pasted image 20240205005635.png]]

#dropout
![[Pasted image 20240205012113.png]]

#BN 
``` python
class BatchNorm1d(Module):
    def __init__(self, dim, eps=1e-5, momentum=0.1, device=None, dtype="float32"):
        super().__init__()
        self.dim = dim
        self.eps = eps
        self.momentum = momentum
        ### BEGIN YOUR SOLUTION
        self.weight = Parameter(init.ones(self.dim), requires_grad=True)
        self.bias = Parameter(init.zeros(self.dim), requires_grad=True)
        self.running_mean = init.zeros(self.dim)
        self.running_var = init.ones(self.dim)
        ### END YOUR SOLUTION

    def forward(self, x: Tensor) -> Tensor:
        ### BEGIN YOUR SOLUTION
        batch_num = x.shape[0]
        feature_num = x.shape[1]
        mean = x.sum(axes=(0,)) / batch_num
        x_ex = x - mean.broadcast_to(x.shape)
        var = (x_ex ** 2).sum(axes=(0,)) / batch_num

        if self.training == False:
            std = (self.running_var + self.eps) ** 0.5
            x_ex = x - self.running_mean.broadcast_to(x.shape)
            x_ = x_ex / std.broadcast_to(x.shape)
            y = self.weight.broadcast_to(x.shape) * x_ + self.bias.broadcast_to(x.shape)
            return y
        else:
            self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * mean.data
            self.running_var = (1 - self.momentum) * self.running_var + self.momentum * var.data

            std = ((var + self.eps) ** 0.5)
            x_ = x_ex / std.broadcast_to(x.shape)
            y = self.weight.broadcast_to(x.shape) * x_ + self.bias.broadcast_to(x.shape)
            return y
        ### END YOUR SOLUTION
```
如上所示，BN也可以用于测试集，不过测试集使用的是全局的mean和variance。
#LN 
LN