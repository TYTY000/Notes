Cuda 10.2++
动机：解决resize问题，提供统一虚拟内存地址功能；擦部分应用只需在其他设备上分配、访问少量内存。

猜测：类似内存池？管理映射？

为了分配内存，虚拟内存管理编程模型公开了以下功能：
1.分配虚拟内存。
2.保留 虚拟地址 范围。
3.将分配的内存映射到 虚拟地址 范围。
4.控制映射范围的访问权限。

#检查是否支持虚拟内存管理
```cpp
int deviceSupportsVmm;
CUresult result = cuDeviceGetAttribute(&deviceSupportsVmm, CU_DEVICE_ATTRIBUTE_VIRTUAL_MEMORY_MANAGEMENT_SUPPORTED, device);
if (deviceSupportsVmm != 0) {
    // `device` supports Virtual Memory Management
}
```
#### #分配VA内存
```c
#define ROUND_UP(x, y) (((x) + (y) - 1) & ~((y) - 1))
CUmemGenericAllocationHandle allocatePhysicalMemory(int device, size_t size) {
  CUmemAllocationProp prop = {
      .type = CU_MEM_ALLOCATION_TYPE_PINNED,
      .requestedHandleTypes = CU_MEM_HANDLE_TYPE_POSIX_FILE_DESCRIPTOR,
      .location =
          {
              .type = CU_MEM_LOCATION_TYPE_DEVICE,
              .id = device,
          },
      .allocFlags =
          {
              .compressionType = CU_MEM_ALLOCATION_COMP_GENERIC,
          }, // memory type.
  };
  size_t granularity = 1024;
  cuMemGetAllocationGranularity(&granularity, &prop,
                                CU_MEM_ALLOC_GRANULARITY_MINIMUM);
  size_t padding = ROUND_UP(size, granularity);
  CUmemGenericAllocationHandle handle;
  cuMemCreate(&handle, padding, &prop, 0);
  // cuMemRelease(handle);
  // CU_DEVICE_ATTRIBUTE_HANDLE_TYPE_POSIX_FILE_DESCRIPTOR_SUPPORTED;
  // CU_DEVICE_ATTRIBUTE_HANDLE_TYPE_WIN32_HANDLE_SUPPORTED;
  return handle;
  // cuMemRelease(handle);
}
```
现在还不能使用，还需要将其映射到VA内存中。
这样分配的内存必须使用cuMemRelease来释放。

使用此法分配的内存是平台不同的，必须在CUmemAllocationProp中指明。
进程间共享的handle需要调用接口cuMemExportToShareableHandle来转换成对应OS的原生handle，接收方需要调用cuMemImportToShareableHandle来转换成可以使用的handle。例如：
```cpp
int deviceSupportsIpcHandle;
#if defined(__linux__)
    cuDeviceGetAttribute(&deviceSupportsIpcHandle, CU_DEVICE_ATTRIBUTE_HANDLE_TYPE_POSIX_FILE_DESCRIPTOR_SUPPORTED, device));
#else
    cuDeviceGetAttribute(&deviceSupportsIpcHandle, CU_DEVICE_ATTRIBUTE_HANDLE_TYPE_WIN32_HANDLE_SUPPORTED, device));
#endif
```
#### Aside：内存类型

#可压缩内存
可用于加速对具有非结构化稀疏性和其他可压缩数据模式的数据的访问。
```c
// 查询功能
int compressionSupported = 0;
cuDeviceGetAttribute(&compressionSupported, CU_DEVICE_ATTRIBUTE_GENERIC_COMPRESSION_SUPPORTED, device);
```
支持的话：prop.allocFlags.compressionType = CU_MEM_ALLOCATION_COMP_GENERIC;

由于硬件资源有限等各种原因，分配可能没有压缩属性，用户需要查询分配的内存的属性并检查压缩属性。
```c
CUmemAllocationPropPrivate allocationProp = {};
cuMemGetAllocationPropertiesFromHandle(&allocationProp, allocationHandle);

if (allocationProp.allocFlags.compressionType == CU_MEM_ALLOCATION_COMP_GENERIC)
{
    // Obtained compressible memory allocation
}
```
#### #保留虚拟地址范围
范围应该至少要大于要保存的实际大小。
```c
CUresult reserve() {
  CUdeviceptr ptr;
  size_t size = 1024;
  // `ptr` holds the returned start of virtual address range reserved.
  CUresult result = cuMemAddressReserve(
      &ptr, size, 0, 0, 0); // alignment = 0 for default alignment
  // cuMemAddressFree(result, size);
  return result;
}
```
#### Aside:使用虚拟内存会引入的别名问题：
#虚拟别名
使用虚拟别名进行写入操作，同对象的别名之间、写完成之前读取到的数据都视为存在不一致。
```c
__global__ void foo1(char *A) {
  *A = 0x1;
}

__global__ void foo2(char *B) {
  printf("%d\n", *B);    // *B == *A == 0x1 assuming foo2 waits for foo1
// to complete before launching
}

cudaMemcpyAsync(B, input, size, stream1);    // Aliases are allowed at
// operation boundaries
foo1<<<1,1,0,stream1>>>(A);                  // allowing foo1 to access A.
cudaEventRecord(event, stream1);
cudaStreamWaitEvent(stream2, event);
foo2<<<1,1,0,stream2>>>(B);
cudaStreamWaitEvent(stream3, event);
cudaMemcpyAsync(output, B, size, stream3);  // Both launches of foo2 and
                                            // cudaMemcpy (which both
                                            // read) wait for foo1 (which writes)
                                            // to complete before proceeding
```
### #地址映射
cuMemMap  cuMemUnmap
```c
void map() {
  CUdeviceptr ptr{reserver()};
  // `ptr`: address in the address range previously reserved by
  // cuMemAddressReserve. `allocHandle`: CUmemGenericAllocationHandle obtained
  size_t size = 1024;
  // by a previous call to cuMemCreate.
  auto allocHandle = allocatePhysicalMemory(0, size);
  CUresult result = cuMemMap(ptr, size, 0, allocHandle, 0);
  // cuMemUnmap(ptr, size);
}
```
#### #控制访问权限
需要显式指定权限范围。
仅分配不指定会导致crash。
```c
void setAccessOnDevice(int device, CUdeviceptr ptr, size_t size) {
  CUmemAccessDesc accessDesc = {
      .location =
          {
              .type = CU_MEM_LOCATION_TYPE_DEVICE,
              .id = device,
          },
      .flags = CU_MEM_ACCESS_FLAGS_PROT_READWRITE,
  };

  // Make the address accessible
  cuMemSetAccess(ptr, size, &accessDesc, 1); // 1 是参数描述的个数
}
```
在这样分配共享的指针上下文前后塞入cudaEnablePeerAccess, cudaDisablePeerAccess就可进行共享访问。

详细查看vectorAddMMAP
