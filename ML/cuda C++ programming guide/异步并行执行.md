在cuda中以下操作都是独立异步的：
CPU、GPU上的计算和数据移动
GPU内和之间的数据移动

对于host独立异步：
内核函数
单设备内的拷贝
64KB以下的HostToDevice拷贝
后缀为Async的拷贝函数
内存设置函数调用
如果通过分析器（Nsight、Visual Profiler）收集硬件计数器，则内核启动是同步的，除非启用了并发内核分析。
如果异步内存副本涉及未页面锁定的主机内存，则它们也可能是同步的。
可以通过CUDA_LAUNCH_BLOCKING = 1来进行调试

并发内核函数执行
在没有启用MPS时，SM只会同时执行一个上下文中的内核，不是严格的并发执行。

#流对象
#### 与线程的区别：
cuda的流有些类似CPU的线程，但是是全局（设备）共享地址空间，本质上是不一样的。
Two commands from different streams cannot run concurrently if any one of the following operations is issued in-between them by the host thread:

    a page-locked host memory allocation,
    a device memory allocation,
    a device memory set,
    a memory copy between two addresses to the same device memory,
    any CUDA command to the NULL stream,
    a switch between the L1/shared memory configurations described in Compute Capability 7.x.

流编程的原则：
独立的操作应尽早执行；
任何形式的同步应尽晚执行。

cuda中的执行逻辑使用cudaStream_t对象来管理的，如：
```cpp
cudaStream_t stream[2];
for (int i = 0; i < 2; ++i)
    cudaStreamCreate(&stream[i]);
float* hostPtr;
cudaMallocHost(&hostPtr, 2 * size);

for (int i = 0; i < 2; ++i) {
    cudaMemcpyAsync(inputDevPtr + i * size, hostPtr + i * size,
                    size, cudaMemcpyHostToDevice, stream[i]);
    MyKernel <<<100, 512, 0, stream[i]>>>
          (outputDevPtr + i * size, inputDevPtr + i * size, size);
    cudaMemcpyAsync(hostPtr + i * size, outputDevPtr + i * size,
                    size, cudaMemcpyDeviceToHost, stream[i]);
}

for (int i = 0; i < 2; ++i)
    cudaStreamDestroy(stream[i]);
```
host和device之间的拷贝用默认流，串行。
nvcc编译器需要使用--default-stream per-thread编译标志，或者使用-DCUDA_API_PER_THREAD_DEFAULT_STREAM=1编译器标志来使得每个host线程绑定一个流。