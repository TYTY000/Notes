降维的目的：
1.降到三维以下有视觉效果
2.减少计算负载
3.减少数据方差
#pca
线性模拟，减少损失的数据量。压缩后的数据量为p。
1.eigenvalue  中心化、协方差矩阵、取前k个最大的特征向量，恢复原数据
2.SVD  A=USV k = (index for sumvar / sum == p)
           A' = U'[:, :k]S'[:k,:k]V'[:k,:]
3.可以加数据，算得快

#MDS
1.获取距离矩阵（通过最近点构图方式获取最短路径）
2.中心化矩阵H= H=I- (1/n) \* i \ * i^T
  内积矩阵B = -1/2 * H * D^2 * H
3.降维坐标EV * Λ^(1/2)

#SNE 
★将欧氏距离转化为条件概率来表征点间相似度（pairwise similarity）。
★使用梯度下降算法来使低维分布学习/拟合高维分布。
★加数据要重算，
★很难算，但是能更好地保留特征
1.用高斯分布作为假定概率分布

![[Pasted image 20240115133407.png]]
pij = pji = 1/2(pij+pji)
![[Pasted image 20240115133601.png]]

2.最小化KL散度（相关熵）

![[Pasted image 20240115133617.png]]
![[Pasted image 20240115135245.png]]
![[Pasted image 20240115135624.png]]
3.梯度下降

![[Pasted image 20240115140450.png]]

#t-SNE 
![[Pasted image 20240115141239.png]]
